{
    "seq_len": 100,
    "embedding_dim": 128,
    "lstm_hidden_size": 128,
    "lstm_num_layers": 1,
    "dropout": 0.5,
    "n_epochs": 50,
    "batch_size": 256,
    "lr": 0.001,
    "filter_sentence_len_geq": 3,
    "filter_sentence_len_leq": 2000,
    "max_tokens": 40,
    "max_eos": 5
}