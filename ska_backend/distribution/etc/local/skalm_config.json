{
    "seq_len": 100,
    "embedding_dim": 256,
    "lstm_hidden_size": 256,
    "lstm_num_layers": 2,
    "dropout": 0.5,
    "n_epochs": 80,
    "batch_size": 512,
    "lr": 0.004,
    "filter_sentence_len_geq": 3,
    "filter_sentence_len_leq": 2000,
    "max_tokens": 160,
    "max_eos": 6
}